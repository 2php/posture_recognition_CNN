// 基于深度学习的姿势识别项目
调试的记录
----------------------------
2018-01-25：
1. h2f/h2f_lw添加avalon_mm_pipeline是不行的，linux的内核boot不了
2. f2h/f2s都是可以增加avalon接口的
3. 在grhd工程的基础上进行修改，现在可以往DDR里面存放MT9D111数据（空间512~544MB）
4. 但是摄像头的配置还有问题（似乎RGB565数据流有问题）
5. 或者也有可能是DDR写入不正确

需要验证：
1. 是摄像头数据流问题？
2. 还是DDR写入的时候数据有丢失？
	（可以写一个调试的接口，按下按钮往DDR里面连续写入XX数据，然后读出，比较正确与否）
	
---------
2018-01-25:
1. 查明原因：是MT9D111的配置有问题，有几个地方是需要delay才行的！
	然后改好以后，在linux里面采集DDR数据，发送到PC显示，正确？
2. 关于ADV7513的配置还有问题！

---------
2018-01-27:
1. 发现DDR读取的时候，数量不对；
	a. 修改mux_port模块，改成了cam_rot_amp项目的即可
	b. 另外，解耦用的2-port的RAM也有时序问题？换成DCFIFO进行解耦（同时参考DCFIFO的q和rdempty）
	c. 再有就是MON_H_rd / MON_rd_req的生成也有问题（总之还是要用状态机控制才安全！）
2. 另外，DDR出来的数据会写入到FIFO里面，但是这个FIFO的VGA读取还有问题？
	应该是综合或者烧录的问题，多编译/烧录几次又可以了
3. 出现视频显示不稳定的情况（水平位移 & 上方噪声条）
	修改了HDMI的时序，又好了

2018-01-31：
1. 将HDMI改成是1024x768输出，65MHz像素时钟
2. ADV7513_DE的赋值需要修改成  ADV7513_DE <= (ADV7513_VCnt<VA && ADV7513_HCnt<HA);
3. 像素时钟的极性是不是也有影响？的确如此！看来走线延时挺大！

----------------------------------
2018-02-02:
1. 发现HPS正在preloader/u-boot的时候，FPGA不能去读写DDR，不然linux启动不了（或者说，u-boot会出错）
2. 发现FPGA把摄像头数据写入进去DDR没有问题（ima+matlab验证），但是ADV7513的HDMI输出数据源有问题
	查明原因：多读了很多的像素点数据！
	但是为什么会多读，似乎是cstate这个状态机的问题――被综合掉了？没有跳转逻辑，这就很奇怪！
	不对，在quartus里面，cstate会被综合成：cstate.0000 / cstate.0001 / cstate.0010 / cstate.0011 / ...
3. 另外，在modelsim仿真中发现，mux-port的port_num_fifo有溢出的可能，调整到4bx4096w大小
4. 还有，DDR中读取video视频数据，只是超前一行，不再超前两行
	读取的启动发生在：超前一行 & HDMI输出正好过了周围白色区域
	统计：DDR中读取出来的像素点数量 == 800
	统计：HDMI申请的像素点数量 == 800
	
-------------
2018-02-02:
1. 发现HDMI<--FIFO<--DDR读取的像素点数量不足够800点？超前2行进行读取？
2. 其实是因为DDR读取的时候太慢造成的，将HDMI输出降低到24fps的帧速，就没有问题了
3. 但是现在的问题在于：图像有水平（漂移造成？）的噪点，不确定是什么原因导致的
	如果只是输出彩条，那么图像很稳定，说明ADV7513 <-- FPGA这里没有问题
	猜测：	1. MT9D111的采集有偏差
			2. DDR读写有偏差
	
	测试：增加一个拨码开关，如果SW[0]==1，那么从DDR里读取出来的数据就是变成彩条，否则保持DDR理数据
			看看到底是DDR读取的问题，还是DDR写入/摄像头输出的问题？
			// 然后，可以根据SW拨码开关的状态，配置写入到line_buffer的数据是video数据/彩条测试图样
			发现：很稳定的彩色条纹！那么问题就出在DDR写入/读取/摄像头采集的问题！
	而通过HPS直接读取DDR中的图像，发现没有所谓的条纹问题，说明问题就出在DDR读取的数据不对！
	
	// 试图将MT9D111的MCLK加到65MHz，能不能提到系统的工作频率？
	无奈之下，选择替换mux-port多端口读写模块，牺牲一半的带宽，总之就是这个模块的问题！
	
	另外，修正了DDR中，512MB~1024MB都是视频采集的缓冲区（8MB/frame x 64frames）
	验证的时候，分别在512MB和1016MB的地方，读取一下DDR里面的数据，做成ima文件，发送到PC，看看有没有视频
	发现linux死机！看来一定要有相应的防范措施，防止linux的OS访问物理内存的高512MB数据，但是可以通过mmap来进行APP访问
	
---------
2018-02-02: 预留出512~1024MB地址的DDR存放视频数据
	尝试解决修正了DDR中，512MB~1024MB都是视频采集的缓冲区（8MB/frame x 64frames），导致linux死机的问题
	在software\spl_bsp\uboot-socfpga\include\configs\socfpga_common.h文件中，修改PHYS_SDRAM_1_SIZE参数，使得preloader和uboot只允许512MB的SDRAM
	不正确！
	实际上，是要在uboot的时候，修改mmcboot这个变量，添加mem=512M就可以实现高512MB空间预留给摄像头数据了
	验证：测试了512 MB 和1016MB 地址的8MB图像数据，发现确实是采集到的图像

---------
2018-02-04：将HDMI输出切割成4块，分别是【原始图像】【骨架图】【光流图】【判别图】
	另外，准备一个礼拜完成【骨架】【光流】的计算

---------
2018-02-06: 光流法的modelsim仿真+matlab绘图验证，另外，修正mux-port模块，提升DDR带宽利用率
			通过设置屏蔽字，巧妙地避开了DCFIFO的rdempty的1-clock延时，为光流法的运作提供了带宽支持
				单端口利用率：0-50%
				多端口利用率：0-100%
				
---------
2018-02-08: 修正了LK光流法模型中的一些小bug
			1. 在ux/vy计算完成后，需要计算速度的大小，这里使用了int_cordic_core模块，但是这个模块是32/16的配置，所以需要作出相应的修正
			2. 不对！其实是cordic算法中，ROM的初始化没有做好！
			3. 应该是VSYNC上升（有效）超前HSYNC（上升/有效）  6个PCLK，但是VSYNC下降又滞后于HSYNC下降6个PCLK
				也就是说：LK光流法模块里面没有来得及读取出DDR里面的（上一帧视频图像）
			4. 调换LK光流法和ADV7513-HDMI输出（对DDR的）读取接口port，将LK光流法的优先级排在HDMI输出的前面，结果发现HDMI输出受阻，看来F2S读取的带宽确实是需要认真考虑的问题
			5. 尝试：将MT9D111的采集时钟降一半，变成36 MHz的，这样整个系统的帧频也下降
			6. 另外，LK光流法读取到的“上一帧”好像有些问题？也不对，应该是1. LK光流结果的存储->2. HDMI输出时候读取LK光流，这两步存在问题
			7. 原来是 video_process 模块没有将 正在写入的块 CURR_FRAME 和上一次写入的块 PREV_FRAME 传递到 OpticalFlowLK 模块中去！
-----------------			
2018-02-12: 在LK光流法模块中增加了动态阈值的功能
	1. 动态阈值 + 4阶均值滤波
	
-------------------------------
2018-02-13：将项目迁移到DE10-Nano开发板下
	集成了MT9D111摄像头采集+LK光流计算+HDMI输出
	480 MB --> Linux OS
	32 MB --> LK Optical Flow
	512 MB --> Video RAM

-------------------------------
2018-02-21: 修改了光流法计算结果的存储格式
			|31|30|		29: 15		|		14:0		|
			|1 |M |     ux			|		vy			|
			[31]的1用来告诉ADV7513的line-buffer，这个数据是光流法的阈值判断结果，只要用[30]扩充就可以了
			其中，M表示Mask，即光流法计算结果，经过动态阈值比较后的判定结果
			ux/vy分别是计算的结果（光流速度），其运算结果缩小8倍得到的结果（即optical_u/optical_v[17:3]）

-------------------------------			
2018-03-02: 增加了HOG+SVM的行人检测代码，能将检测的结果保存到DDR的448MB~480 MB区间内
			存储的格式为：   [aa][bbbbbbbb][hhhhhhhhhhh][vvvvvvvvvvv]
			其中，aa=00:无效数据/ aa=01:表示1/1比例尺 / aa=10：表示1/2比例尺  /  aa=11:表示1/4比例尺
			bbbbbbbb = score/4096，直接移位12bit，应该足够存下了
			最后，hhhhhhhhh/vvvvvvvv就是bbox左上角所处的坐标位置
			另外，发现两个大问题：
			1. 板子的资源可能不太够
			2. OpenCL和普通的rtl怎么一同进行编译
			3. 怎么在14.0下开发OpenCL程序
	
	448 MB --> Linux OS
	32 MB --> Pedestrian Detection Result
	32 MB --> LK Optical Flow
	512 MB --> Video RAM		
--------------------
2018-03-03: 发现SVM判决器中的数据有溢出的情况
	1. 8-bit有符号数保存SVM中的w/b参数，所有参数x64取整（floor）
	2. 调整hog_svm_pd_rtl模块中的输出移位
	3. 调整hog_svm_pd_800x600/400x300/200x150中的行人检测阈值
	
	另外，HSG-SVM的参数，一定要用round进行【四舍五入】取整
	如果简单的ceil/floor进行向上/向下取整，会存在累积误差
	
	此外，1：2和1：4两个缩放后的图像中，HSG特征和matlab的结果有很大的区别，将近±33%，几乎就是完全不对的
	1：1原始图像的HSG特征和matlab结果差不多是±8%的误差
	
	
---------------
2018-03-06：使用Avalon-MM master/slave translator，将HPS和FPGA之间的AXI接口转换成Avalon接口
	1. F2S直接Avalon-MM，外部MT9D111摄像头采集&LK光流计算&行人检测结果
	2. F2H通过Avalon-MM-Master-Translator，实现HDMI数据的读取
	3. H2F通过Avalon-MM-Slave-Translator，实现HPS向FPGA传输数据，但是速率很慢，应该是AXI/Avalon协议转换造成的
	PS！后续应该要有AXI接口数据的直接读取，测试一下传输速率
	
----------
2018-03-07: 查明h2f/h2f_lw速度较慢的原因：Linux的问题
	1. 另外，通过Avalon-MM-Slave-Translator转接出来的h2f.lw接口，不会产生avalon_write信号！
	2. 发现将h2f传输数据量减小，h2f_lw就可以了
	3. 实测下来，h2f/h2f_lw都是低速的，询问工程师，理由是――Linux调度的问题
	4. 建议：fpga作为Avalon的master，通过f2h_axi_slave读取显示的缓存
	
	
----------
2018-03-16：添加了一份整体模块间调用的图readme(module).txt

-----------
2018-03-19: NPU架构集成、指令完成信号的交互
	1. 集成NPU架构进入系统工程，
	2. 同时通过H2F接口传输指令&FPGA超时等待机制确认指令传输完成
	3. 通过PIO交换NPU指令完成与否，以及MT9D111摄像头正在写入的区间【当然，这两个PIO信号必须set_false_path，否则时序违例】
	4. 增加NPU执行时钟周期计数到HPS.PIO的连接，用于确定NPU执行时间
	
-----------------
2018-03-19:
	1. 在NPU单元内部加入指令执行时间计算单元
	2. 修正了video_process模块中，HDMI输出的时候选取的视频来源（主要是0x09800000的行人检测加框结果）
	3. 行人检测效果不是特别的好，考虑原因如下：
		a. SVM训练样本挑选问题（正样本数量不够/负样本数量太多），改成2000/6000
		b. SVM定点算法误差较大，精度不够，改成10-bit小数位
		c. HSG的特征不足以解决此问题？暂时先不考虑这个可能性，因为有论文支撑这个HSG的正确/可行性
		【另外，需要将PD结果汇总写入DDR的score打分压缩1/16才可以，否则会有溢出的可能】
	4. 在HPS上用C语言实现了NMS非极大值抑制算法
		将内存空间0x2600_0000~0x2800_0000这32MB空间用于行人检测结果显示，有几种方案：
		a. 先将内存空间清空，然后将框内的图像输出到内存空间==>HDMI
		b. 将最新的图像复制到内存空间，并将框框打上去==>HDMI
		两种方案各有利弊，a方案速度快，b方案观察起来稳定，暂时先选择b方案
		
		
----------------
2018-03-21: 遇到了DDR读写带宽不够的问题！开放更多的f2s端口！
	1. 将HPS的C程序写成了多线程操作，MakeFIle修正，添加-lpthread选项
	3. 增加SVM参数的定点精度，到16bit整形定点存储，其中14-bit小数位
	4. 调整SDC文件约束，将摄像头输入时钟的频率设定在40 MHz，方便后端PR处理
	5. 开放两个f2s端口如下：
		f2s0 <----> LK光流法的读写 & 行人检测结果写入
		f2s1 <----> 视频的缓存 & HDMI输出
		f2h  <----> NPU单元的数据读写
		h2f  -----> 发送NPU指令
		h2f.lw <--- 接收NPU状态
	
P.S. 	试图将调用DDR读写控制器IP核的mux-port模块改写成burst传输的模式（假设最大的burst长度为4）【未果】
		注意DCFIFO的rdusedw/rdempty/rdfull等信号相对于rdreq存在的延时！
		测试环境：只剩下MT9D111视频输入/ADV7513视频输出，看看整个系统的极限频率
					然后调整mux-port的burst模式，看看视频采集是否正确，再看看系统的极限频率能否提高
		但是还要考虑burst的时候，有没有可能触碰到存储的边界！（所以mux-port模块还要有输入边界参数！）
		正确的burst条件是：rdusedw>=4 && 没有到达边界，这样可以启动burst x2，可以提升DDR控制器的读写带宽
	
----------------
2018-03-22: 修正了系统的时序
	1. 将HDMI读取DDR的时钟降低到80MHz
	2. NPU执行时间到HPS的接口也要set_false_path才行，或者需要DCFIFO进行跨时钟域的同步处理
	
--------------
2018-03-23: 光流计算中，上一帧视频没有完全读取出来！
	1. 使用更加高频的时钟去读取上一帧视频，这样的话，LK光流模块中的跨时钟域数据的同步就要用DPRAM来做了
	
----------
2018-03-26: 
	1. 行人加框结果也要缓存到2个内存块中，HPS通过PIO将正在写入的内存块记号传递给FPGA逻辑
	
---------
2018-03-27: 
	1. 为了减少M10K的占用，在行人检测模块中，SVM的VUT（待检测向量）需要拆分成H/L两半部分
	
2018-03-27: 试图减少资源占用，未果！
	1. 添加了一条RGB565转成灰度图像的指令[NPU]
    
---------
2018-03-29: 试图只用一个框将图像中的行人检测出来，未果
    1. 添加了光流法加框的算法（多尺度扫描）
    2. 怎么将HOG+SVM的行人检测方案和LK光流法的检测结果融合起来？
        LK光流：动态，运动物体准确，但是行人减速、只挥动手臂就会导致框缩小
        行人检测：静态，加框不准确，但是不会受到行人运动速度的影响
        
------------
2018-03-30: 添加NPU的指令RAM
    HPS通过H2F接口传输NPU指令，包括：
    1. 128'D0   表示NOP指令
    2. 128'D1   表示清空RAM的head指示（初始化指令RAM之前一定要传递该指令）
    3. 128'D2   表示执行RAM里面的指令（逐条执行）
    
2018-03-30：更新了SDC时序约束文件

---------------
2018-03-30：增加了框中数据的采集代码。

-----------
2018-04-07: 
	1. 增加了ADDs/SUBs两条指令
	2. 验证了基于NPU指令的CNN实现
	3. 增加了NPU指令发送、CNN网络参数存储、CNN网络输入数据等C语言接口
	
---------------
2018-04-09: 
	1. 将HPS端的C程序项目分模块加以保存和编译
	2. 整个系统测试运行，考察一下内容：
		1. NPU指令发布是否正确（正确）
		2. CNN输入数据是否正确
		3. CNN参数配置是否正确
		4. CNN计算过程是否正确（消耗时间大约是0.14 s ~ 0.25 s）
	3. linux下面的换行符是\n，windows下面的是\r\n
	4. 在python生成的sim_source文件夹中，有相应的CNN参数 & 原始数据的list文件
		这些文件的命名依照[sp-xx-label-yy.list]的规则，能够很方便的进行CNN硬件化验证
		通过这种“输入训练集样本进行CNN运行检验”的方法，可以确定问题出在【2,3,4】中
		最后，偶然发现：存储CNN参数的空间在mmap的时候，SPAN不够！
		修改之后，训练集数据可以跑通了
		
	5. 最后不得不承认！CNN过拟合了！
	
----------------
2018-04-18:
	1. 将NPU模块的读写两路请求端口分配到f2s0/f2h两路中；不要影响光流计算/HDMI输出;
	2. 将HDMI输出调整，右下角输出action-word，之后留给判别结果；
	3. 显示的顶部留给[posture recognition system]作为标语title
	
-----------
2018-05-23
	测试github能不能上传